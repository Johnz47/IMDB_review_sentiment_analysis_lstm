{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e570958-7409-4a75-b054-94b6810597dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Using CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (NVIDIA GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available. You can use GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3560ecda-9222-4457-9e93-1c8f0cb13351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential libraries and functions\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759d5b99-987e-4649-bc87-dffa38c1ccc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'absl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\__init__.py:37\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'absl'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099dc61-a6c9-4351-98d1-be1183a512d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importing essential libraries and functions\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf03cfd8-b5ea-4b3d-bb2b-7246d56937e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense\n",
    "from tensorflow.keras.layers import Flatten, GlobalMaxPooling1D, Embedding, Conv1D, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a524938-7608-4f6e-bb50-3ee3849141b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27fc8322-f699-4f4f-aad6-0d90fd7975da",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = pd.read_csv(\"IMDB_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7401eb91-eadc-4d2a-9174-32d1576194aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4153e29-0cc6-42ca-aa7b-2022ed5906b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b07e380-388b-41c7-9dea-36ebe1c82f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGwCAYAAAC0HlECAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAALBhJREFUeJzt3Qd0VGX+//FvQi8m9BKIAelgCBowIEUpC4i6oqC0VUDKwoKUKG1FiuByxKUtIqhIc8EFVFRAKUaKQACNIj0CwoKHKhI6IQnzP9/nt3f+MyTAAyZkMnm/zrlncu99cudJzrnJZ552A1wul0sAAABwU4E3Pw0AAABFaAIAALBAaAIAALBAaAIAALBAaAIAALBAaAIAALBAaAIAALCQ06YQbu3atWty9OhRueeeeyQgICCzqwMAACzocpXnz5+XkJAQCQy8eVsSoSmdaGAKDQ3N7GoAAIA7cOTIESlbtuxNyxCa0om2MDm/9KCgoMyuDgAAsHDu3DnT6OH8H78ZQlM6cbrkNDARmgAAyFpshtYwEBwAAMACoQkAAMACoQkAAMACoQkAAMACoQkAAMACoQkAAMACoQkAAMACoQkAAMACoQkAAMACoQkAAMACoQkAAMDXQ9O4ceOkTp065iF5JUqUkNatW0t8fLxXmUcffdQ8D8Zz69Wrl1eZw4cPy+OPPy758+c31xk0aJAkJyd7lVm7dq08+OCDkidPHqlYsaLMmTMnVX2mTZsm5cqVk7x580pUVJRs3bo1g35yAACQ1WRqaFq3bp306dNHNm/eLKtXr5akpCRp3ry5XLx40atcjx495NixY+5t/Pjx7nMpKSkmMF29elU2bdokc+fONYFoxIgR7jIHDx40ZRo3bizbtm2TAQMGSPfu3WXlypXuMgsXLpTo6GgZOXKk/PDDDxIRESEtWrSQkydP3qXfBgAA8GUBLpfLJT7i1KlTpqVIw1SjRo3cLU21atWSyZMnp/k9X331lTzxxBNy9OhRKVmypDk2Y8YMGTJkiLle7ty5zdfLly+XnTt3ur+vffv2kpCQICtWrDD72rKkrV5vv/222b927ZqEhobKSy+9JEOHDr1l3c+dOyfBwcFy9uxZCQoKSpffBwAAyFi38//bp8Y0aYVVkSJFvI7Pnz9fihUrJvfff78MGzZMLl265D4XGxsr4eHh7sCktIVIfwm7du1yl2nWrJnXNbWMHlfaShUXF+dVJjAw0Ow7Za6XmJho3sNzAwAA/iun+Aht2dFus/r165tw5OjYsaOEhYVJSEiIbN++3bQa6binTz/91Jw/fvy4V2BSzr6eu1kZDTqXL1+WM2fOmG6+tMrs3bv3huOxRo8eLXdb5KB5d/09AV8X99YL4g+4vwHfvr99JjTp2CbtPtuwYYPX8Z49e7q/1hal0qVLS9OmTeXAgQNSoUIFySza4qVjoBwawLQ7DwAA+CefCE19+/aVZcuWyfr166Vs2bI3Latjj9T+/ftNaCpVqlSqWW4nTpwwr3rOeXWOeZbRvst8+fJJjhw5zJZWGeca19NZeLoBAIDsIVPHNOkYdA1MS5YskW+++UbKly9/y+/R2W9KW5xUvXr1ZMeOHV6z3HQmngai6tWru8vExMR4XUfL6HGlg8UjIyO9ymh3oe47ZQAAQPaWM7O75BYsWCCff/65WavJGYOko9i1BUi74PR8q1atpGjRomZM08CBA83Mupo1a5qyukSBhqPnn3/eLEWg1xg+fLi5ttMSpOs66ay4wYMHy4svvmgC2qJFi8yMOod2tXXu3Flq164tDz30kJmtp0sfdO3aNZN+OwAAwJdkamiaPn26e1kBT7Nnz5YuXbqYFqCvv/7aHWB0zFCbNm1MKHJot5p27fXu3du0ChUoUMCEn9dff91dRluwNCBp4JoyZYrpApw5c6aZQedo166dWaJA13fS4KXLHOhyBNcPDgcAANmTT63TlJXdrXWamF0D+Pbsmj+C+xu4+/d3ll2nCQAAwFcRmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAAHw9NI0bN07q1Kkj99xzj5QoUUJat24t8fHxXmWuXLkiffr0kaJFi0rBggWlTZs2cuLECa8yhw8flscff1zy589vrjNo0CBJTk72KrN27Vp58MEHJU+ePFKxYkWZM2dOqvpMmzZNypUrJ3nz5pWoqCjZunVrBv3kAAAgq8nU0LRu3ToTiDZv3iyrV6+WpKQkad68uVy8eNFdZuDAgbJ06VJZvHixKX/06FF55pln3OdTUlJMYLp69aps2rRJ5s6dawLRiBEj3GUOHjxoyjRu3Fi2bdsmAwYMkO7du8vKlSvdZRYuXCjR0dEycuRI+eGHHyQiIkJatGghJ0+evIu/EQAA4KsCXC6XS3zEqVOnTEuRhqNGjRrJ2bNnpXjx4rJgwQJp27atKbN3716pVq2axMbGSt26deWrr76SJ554woSpkiVLmjIzZsyQIUOGmOvlzp3bfL18+XLZuXOn+73at28vCQkJsmLFCrOvLUva6vX222+b/WvXrkloaKi89NJLMnTo0FR1TUxMNJvj3LlzprzWOSgoKMN+R5GD5mXYtYGsKu6tF8QfcH8Dd//+1v/fwcHBVv+/fWpMk1ZYFSlSxLzGxcWZ1qdmzZq5y1StWlXuvfdeE5qUvoaHh7sDk9IWIv0l7Nq1y13G8xpOGeca2kql7+VZJjAw0Ow7ZdLqWtRfsrNpYAIAAP7LZ0KTtuxot1n9+vXl/vvvN8eOHz9uWooKFSrkVVYDkp5zyngGJue8c+5mZTRYXb58WX777TfTzZdWGeca1xs2bJgJec525MiRP/w7AAAAviun+Agd26TdZxs2bJCsQAeU6wYAALIHn2hp6tu3ryxbtkzWrFkjZcuWdR8vVaqU6TrTsUeedPacnnPKXD+bztm/VRntu8yXL58UK1ZMcuTIkWYZ5xoAACB7y9TQpGPQNTAtWbJEvvnmGylfvrzX+cjISMmVK5fExMS4j+mSBLrEQL169cy+vu7YscNrlpvOxNNAVL16dXcZz2s4ZZxraBegvpdnGe0u1H2nDAAAyN5yZnaXnM6M+/zzz81aTc74IR1YrS1A+tqtWzezFIAODtcgpLPZNMjozDmlSxRoOHr++edl/Pjx5hrDhw8313a6z3r16mVmxQ0ePFhefPFFE9AWLVpkZtQ59D06d+4stWvXloceekgmT55slj7o2rVrJv12AACAL8nU0DR9+nTz+uijj3odnz17tnTp0sV8PWnSJDOTTRe11Cn+OuvtnXfecZfVbjXt2uvdu7cJUwUKFDDh5/XXX3eX0RYsDUi65tOUKVNMF+DMmTPNtRzt2rUzSxTo+k4avGrVqmWWI7h+cDgAAMiefGqdpqzsdtZ5+CNYxwVIjXWaAP8VxzpNAAAAWQuhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwAKhCQAAwNdD0/r16+XJJ5+UkJAQCQgIkM8++8zrfJcuXcxxz61ly5ZeZX7//Xfp1KmTBAUFSaFChaRbt25y4cIFrzLbt2+Xhg0bSt68eSU0NFTGjx+fqi6LFy+WqlWrmjLh4eHy5ZdfZtBPDQAAsqJMDU0XL16UiIgImTZt2g3LaEg6duyYe/voo4+8zmtg2rVrl6xevVqWLVtmgljPnj3d58+dOyfNmzeXsLAwiYuLk7feektGjRol7733nrvMpk2bpEOHDiZw/fjjj9K6dWuz7dy5M4N+cgAAkNXkzMw3f+yxx8x2M3ny5JFSpUqleW7Pnj2yYsUK+e6776R27drm2NSpU6VVq1byz3/+07RgzZ8/X65evSqzZs2S3LlzS40aNWTbtm0yceJEd7iaMmWKCWeDBg0y+2PGjDEh7O2335YZM2ak+88NAACyHp8f07R27VopUaKEVKlSRXr37i2nT592n4uNjTVdck5gUs2aNZPAwEDZsmWLu0yjRo1MYHK0aNFC4uPj5cyZM+4y+n2etIwev5HExETTiuW5AQAA/+XToUlbf+bNmycxMTHy5ptvyrp160zLVEpKijl//PhxE6g85cyZU4oUKWLOOWVKlizpVcbZv1UZ53xaxo0bJ8HBwe5Nx0oBAAD/landc7fSvn1799c6OLtmzZpSoUIF0/rUtGnTTK3bsGHDJDo62r2vLU0EJwAA/JdPtzRd77777pNixYrJ/v37zb6OdTp58qRXmeTkZDOjzhkHpa8nTpzwKuPs36rMjcZSOWOtdMae5wYAAPxXlgpNv/76qxnTVLp0abNfr149SUhIMLPiHN98841cu3ZNoqKi3GV0Rl1SUpK7jA7y1jFShQsXdpfRLkBPWkaPAwAAZHpo0vWUdCabburgwYPm68OHD5tzOptt8+bNcujQIRNqnnrqKalYsaIZpK2qVatmxj316NFDtm7dKhs3bpS+ffuabj2dOac6duxoBoHrcgK6NMHChQvNbDnPrrX+/fubWXgTJkyQvXv3miUJvv/+e3MtAACATA9NGkweeOABsykNMvr1iBEjJEeOHGZRyj//+c9SuXJlE3oiIyPl22+/NV1jDl1SQBel1DFOutRAgwYNvNZg0kHaq1atMoFMv//ll1821/dcy+nhhx+WBQsWmO/TdaM+/vhjs9Dm/ffff5d/IwAAwFcFuFwuV2ZXwh/oQHANaGfPns3Q8U2Rg+Zl2LWBrCrurRfEH3B/A3f//r6d/99ZakwTAABAZiE0AQAAZFRoatKkiZm1llYTl54DAADwN3cUmnRxSX2e2/WuXLliBmoDAABk6xXBdTabY/fu3V6PGdFHm+i0/TJlyqRvDQEAALJaaKpVq5YEBASYLa1uuHz58snUqVPTs34AAABZLzTpWke6QoE+zkQXkyxevLj7nC4gqQ/P1fWVAAAAsnVoCgsLM6/6mBIAAIDs5LZCk6d9+/bJmjVrzANzrw9RuuI2AACAZPfQ9P7770vv3r2lWLFiUqpUKTPGyaFfE5oAAIC/uaPQNHbsWHnjjTdkyJAh6V8jAAAAf1mn6cyZM/Lss8+mf20AAAD8KTRpYFq1alX61wYAAMCfuucqVqwor732mmzevFnCw8MlV65cXuf79euXXvUDAADIuqHpvffek4IFC8q6devM5kkHghOaAACAv7mj0KSLXAIAAGQndzSmCQAAILu5o5amF1988abnZ82adaf1AQAA8J/QpEsOeEpKSpKdO3dKQkJCmg/yBQAAyJahacmSJamO6aNUdJXwChUqpEe9AAAA/HNMU2BgoERHR8ukSZPS65IAAAD+ORD8wIEDkpycnJ6XBAAAyLrdc9qi5MnlcsmxY8dk+fLl0rlz5/SqGwAAQNYOTT/++GOqrrnixYvLhAkTbjmzDgAAINuEpjVr1qR/TQAAAPwtNDlOnTol8fHx5usqVaqY1iYAAAB/dEcDwS9evGi64UqXLi2NGjUyW0hIiHTr1k0uXbqU/rUEAADIiqFJB4Lrg3qXLl1qFrTU7fPPPzfHXn755fSvJQAAQFbsnvvkk0/k448/lkcffdR9rFWrVpIvXz557rnnZPr06elZRwAAgKzZ0qRdcCVLlkx1vESJEnTPAQAAv3RHoalevXoycuRIuXLlivvY5cuXZfTo0eYcAACAv7mj7rnJkydLy5YtpWzZshIREWGO/fTTT5InTx5ZtWpVetcRAAAga4am8PBw2bdvn8yfP1/27t1rjnXo0EE6depkxjUBAAD4mzsKTePGjTNjmnr06OF1fNasWWbtpiFDhqRX/QAAALLumKZ3331Xqlatmup4jRo1ZMaMGelRLwAAgKwfmo4fP24WtryergiuD+4FAADwN3cUmkJDQ2Xjxo2pjusxXRkcAADA39zRmCYdyzRgwABJSkqSJk2amGMxMTEyePBgVgQHAAB+6Y5C06BBg+T06dPyt7/9Ta5evWqO5c2b1wwAHzZsWHrXEQAAIGuGpoCAAHnzzTfltddekz179phlBipVqmTWaQIAAPBHdxSaHAULFpQ6deqkX20AAAD8aSA4AABAdkNoAgAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAgAA8PXQtH79ennyySclJCREAgIC5LPPPvM673K5ZMSIEVK6dGnJly+fNGvWTPbt2+dV5vfff5dOnTpJUFCQFCpUSLp16yYXLlzwKrN9+3Zp2LCh5M2bV0JDQ2X8+PGp6rJ48WKpWrWqKRMeHi5ffvllBv3UAAAgK8rU0HTx4kWJiIiQadOmpXlew82//vUvmTFjhmzZskUKFCggLVq0kCtXrrjLaGDatWuXrF69WpYtW2aCWM+ePd3nz507J82bN5ewsDCJi4uTt956S0aNGiXvvfeeu8ymTZukQ4cOJnD9+OOP0rp1a7Pt3Lkzg38DAAAgqwhwaXOOD9CWpiVLlpiworRa2gL18ssvyyuvvGKOnT17VkqWLClz5syR9u3by549e6R69ery3XffSe3atU2ZFStWSKtWreTXX3813z99+nR59dVX5fjx45I7d25TZujQoaZVa+/evWa/Xbt2JsBp6HLUrVtXatWqZQKbDQ1nwcHBpo7a6pVRIgfNy7BrA1lV3FsviD/g/gbu/v19O/+/fXZM08GDB03Q0S45h/5QUVFREhsba/b1VbvknMCktHxgYKBpmXLKNGrUyB2YlLZWxcfHy5kzZ9xlPN/HKeO8T1oSExPNL9pzAwAA/stnQ5MGJqUtS5503zmnryVKlPA6nzNnTilSpIhXmbSu4fkeNyrjnE/LuHHjTIhzNh0rBQAA/JfPhiZfN2zYMNOU52xHjhzJ7CoBAIDsGJpKlSplXk+cOOF1XPedc/p68uRJr/PJyclmRp1nmbSu4fkeNyrjnE9Lnjx5TN+n5wYAAPyXz4am8uXLm9ASExPjPqbjhnSsUr169cy+viYkJJhZcY5vvvlGrl27ZsY+OWV0Rl1SUpK7jM60q1KlihQuXNhdxvN9nDLO+wAAAGRqaNL1lLZt22Y2Z/C3fn348GEzm27AgAEyduxY+eKLL2THjh3ywgsvmBlxzgy7atWqScuWLaVHjx6ydetW2bhxo/Tt29fMrNNyqmPHjmYQuC4noEsTLFy4UKZMmSLR0dHuevTv39/MupswYYKZUadLEnz//ffmWgAAACpnZv4aNJg0btzYve8Emc6dO5tlBQYPHmyWAtB1l7RFqUGDBibc6AKUjvnz55tw07RpUzNrrk2bNmZtJ4cO0l61apX06dNHIiMjpVixYmbBTM+1nB5++GFZsGCBDB8+XP7+979LpUqVzJIE999//137XQAAAN/mM+s0ZXWs0wRkHtZpAvxXHOs0AQAAZC2EJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAgKwemkaNGiUBAQFeW9WqVd3nr1y5In369JGiRYtKwYIFpU2bNnLixAmvaxw+fFgef/xxyZ8/v5QoUUIGDRokycnJXmXWrl0rDz74oOTJk0cqVqwoc+bMuWs/IwAAyBp8OjSpGjVqyLFjx9zbhg0b3OcGDhwoS5culcWLF8u6devk6NGj8swzz7jPp6SkmMB09epV2bRpk8ydO9cEohEjRrjLHDx40JRp3LixbNu2TQYMGCDdu3eXlStX3vWfFQAA+K6c4uNy5swppUqVSnX87Nmz8sEHH8iCBQukSZMm5tjs2bOlWrVqsnnzZqlbt66sWrVKdu/eLV9//bWULFlSatWqJWPGjJEhQ4aYVqzcuXPLjBkzpHz58jJhwgRzDf1+DWaTJk2SFi1a3LBeiYmJZnOcO3cuQ35+AADgG3y+pWnfvn0SEhIi9913n3Tq1Ml0t6m4uDhJSkqSZs2auctq1929994rsbGxZl9fw8PDTWByaBDSgLNr1y53Gc9rOGWca9zIuHHjJDg42L2Fhoam688NAAB8i0+HpqioKNOdtmLFCpk+fbrpSmvYsKGcP39ejh8/blqKChUq5PU9GpD0nNJXz8DknHfO3ayMBqvLly/fsG7Dhg0zrV3OduTIkXT7uQEAgO/x6e65xx57zP11zZo1TYgKCwuTRYsWSb58+TK1bjpoXDcAAJA9+HRL0/W0Valy5cqyf/9+M85JB3gnJCR4ldHZc84YKH29fjads3+rMkFBQZkezAAAgO/IUqHpwoULcuDAASldurRERkZKrly5JCYmxn0+Pj7ejHmqV6+e2dfXHTt2yMmTJ91lVq9ebQJR9erV3WU8r+GUca4BAADg86HplVdeMUsJHDp0yCwZ8PTTT0uOHDmkQ4cOZvB1t27dJDo6WtasWWMGhnft2tWEHZ05p5o3b27C0fPPPy8//fSTWUZg+PDhZm0np2utV69e8ssvv8jgwYNl79698s4775juP13OAAAAIEuMafr1119NQDp9+rQUL15cGjRoYJYT0K+VLgsQGBhoFrXU6f86601Dj0MD1rJly6R3794mTBUoUEA6d+4sr7/+uruMLjewfPlyE5KmTJkiZcuWlZkzZ950uQEAAJD9BLhcLldmV8If6Gw7bf3SmXTa/ZdRIgfNy7BrA1lV3FsviD/g/gbu/v19O/+/fbp7DgAAwFcQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmgAAACwQmq4zbdo0KVeunOTNm1eioqJk69atmV0lAADgAwhNHhYuXCjR0dEycuRI+eGHHyQiIkJatGghJ0+ezOyqAQCATEZo8jBx4kTp0aOHdO3aVapXry4zZsyQ/Pnzy6xZszK7agAAIJPlzOwK+IqrV69KXFycDBs2zH0sMDBQmjVrJrGxsanKJyYmms1x9uxZ83ru3LkMrWdK4uUMvT6QFWX0fXe3cH8Dd//+dq7vcrluWZbQ9D+//fabpKSkSMmSJb2O6/7evXtTlR83bpyMHj061fHQ0NAMrSeA1IKn9srsKgDI4vf3+fPnJTg4+KZlCE13SFukdPyT49q1a/L7779L0aJFJSAgIFPrhoynn0w0IB85ckSCgoIyuzoA0hH3d/bicrlMYAoJCbllWULT/xQrVkxy5MghJ06c8Dqu+6VKlUpVPk+ePGbzVKhQoQyvJ3yL/kHljyrgn7i/s4/gW7QwORgI/j+5c+eWyMhIiYmJ8Wo90v169eplat0AAEDmo6XJg3a3de7cWWrXri0PPfSQTJ48WS5evGhm0wEAgOyN0OShXbt2curUKRkxYoQcP35catWqJStWrEg1OBzQrlldz+v6LloAWR/3N24kwGUzxw4AACCbY0wTAACABUITAACABUITAACABUITcBvWrl1rFi9NSEi4ably5cqZ2ZcA/NuoUaPMpCFkDwwEB27zGYW68rvOqNTwNGfOHBkwYECqEKWzMAsUKGAe+AzAP+g9v2TJEmndurX72IULF8xzSPVpEPB/LDkA3OYiqGmtEH+94sWL35X6AMhcBQsWNBuyB7rn4HceffRR6du3r9l0aXx9RM5rr73mfoL1mTNn5IUXXpDChQublqDHHntM9u3b5/7+//73v/Lkk0+a89paVKNGDfnyyy9Tdc/p17rw6dmzZ80x3bSp/vruuY4dO5o1wDwlJSWZes2bN8+9+rw+BLp8+fKSL18+iYiIkI8//viu/c4AX7+n+/XrJ4MHD5YiRYqYDy7Ovab0fuzevbv5sKKPPWnSpIn89NNPXtcYO3aslChRQu655x5TdujQoV7dat9995386U9/Mvel/t145JFH5IcffnCf13taPf300+Zed/Y9u+dWrVolefPmTdXy3L9/f1Mnx4YNG6Rhw4bmXtdn3OnPpgspw/cRmuCX5s6dKzlz5pStW7fKlClTZOLEiTJz5kxzrkuXLvL999/LF198IbGxsSZMtWrVygQZ1adPH9Pcvn79etmxY4e8+eabaX6SfPjhh00w0j/Sx44dM9srr7ySqlynTp1k6dKlphnfsXLlSrl06ZL5A6w0MGmAmjFjhuzatUsGDhwof/nLX2TdunUZ+FsCstY9rR9itmzZIuPHj5fXX39dVq9ebc49++yzcvLkSfnqq68kLi5OHnzwQWnatKnpSlfz58+XN954w9zLev7ee++V6dOne11fH9iqT4TQQLN582apVKmS+bugx51QpWbPnm3udWffk76nPoP0k08+cR9LSUmRhQsXmr8D6sCBA9KyZUtp06aNbN++3ZzT99QPecgCdEwT4E8eeeQRV7Vq1VzXrl1zHxsyZIg59vPPP2tzk2vjxo3uc7/99psrX758rkWLFpn98PBw16hRo9K89po1a8z3nzlzxuzPnj3bFRwcnKpcWFiYa9KkSebrpKQkV7FixVzz5s1zn+/QoYOrXbt25usrV6648ufP79q0aZPXNbp162bKAdmd3tMNGjTwOlanTh1zX3/77beuoKAgcx95qlChguvdd981X0dFRbn69Onjdb5+/fquiIiIG75nSkqK65577nEtXbrUfUzv/SVLlniVGzlypNd1+vfv72rSpIl7f+XKla48efK4/2bofd2zZ0+va+jPEBgY6Lp8+bLV7wOZh5Ym+KW6deuaJnSHPnRZu+B2795tWqCioqLc53QAZ5UqVWTPnj1mX5vKtSm/fv365lEK+mnwj9D3e+6558ynXaXN8J9//rn7k+f+/ftNq5N2DTjjI3TTlif9VApApGbNml77pUuXNq1L2g2nrbh6H3vePwcPHnTfP/Hx8eZ5op6u3z9x4oT06NHDtDBp95y2IOt1Dx8+fFv11Ptau+6PHj1q9vW+f/zxx00LlNL66gQSz7q2aNHCdNFrneHbGAgOXEfHO+gfseXLl5sxCtp1NmHCBHnppZfu+Jr6h1THSOgfee1S0LEM2kSvnG47fb8yZcp4fR/PvgL+T65cubz29UORBg29fzRAaVC5nhNUbGjX3OnTp013flhYmLn39MOWzpi9HXXq1JEKFSrIf/7zH+ndu7eZbachyaH1/etf/2o+nF1Puw3h2whN8Es67sGTM0ahevXqkpycbM7rmCSlfyj1k6iec+jgzF69eplt2LBh8v7776cZmnQ2nY5ZuBV9L72mjl/QcRc6BsP5J6Dvq3+g9ROtBisA9nT8kj5gXVt0ncHZ19OWZB2DpBNAHNePSdq4caO88847ZhyTOnLkiPz2229eZfSetbnf9UOStjCVLVtWAgMDTUuTZ321xbtixYq3/bMi89E9B7+kASQ6OtqEoY8++kimTp1qZrBocHrqqadMM7wOvtSmch1wrS08elzpuks6UFubynX2zJo1a6RatWppvo/+kdZPjjExMeYPrHaz3YjOotOB3trS5HTNKZ3NowPIdfC3DnbVLgV9X62z7gO4sWbNmpkWIV07SVuGDx06JJs2bZJXX33VTPhQ+oHngw8+MPeTdtNr97t2u3t24evfhg8//NB00+uHKr1HtUX4+vtd73UNaToL90b0e/Ue1sHnbdu29WoxHjJkiKmfDvzetm2bqY921zMQPGsgNMEv6SfKy5cvm3ELOhtOA1PPnj3ds18iIyPliSeeMH9sdXynLingtPzoJ0n9Hg1K2oVWuXJl8wn0Ri1I2hqlSwrodGed1XOzP6T6CVMDmo6X8jRmzBizLIJ2BTrvq911ugQBgBvT4KP3b6NGjcwSIHq/tm/f3iwdoovQOveethjrhxNt6dEPRDqLVpcHcGio0iCk559//nnTfaZLFHjSbnr90KOtxg888MAN66StSPq3R4OZ5wckZ2yWzor9+eefzbIDep0RI0ZISEhIuv9ukP5YERx+uaaLrpvCY0wA3IhOvND1nrR1CbDFmCYAgF/TbnPtGtcJHjly5DBd9l9//bV7nSfAFqEJAJAtuvB0jNGVK1fMwHBdgFLHQwG3g+45AAAACwwEBwAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAgAAsEBoAoA06CMzWCAVgCdCE4BsTZ9AX6hQoVTH9YGuzqN3MtPatWvNOkMJCQmZXRUg22NxSwBIgz5LEAA80dIEwOd9/PHHEh4ebp46X7RoUbOS88WLF825mTNnmocc68NXq1at6vVwZX3ivbbSfPrpp9K4cWPJnz+/RERESGxsrLsVRx/yevbsWVNOt1GjRqXZPafn3n33XfOgZ72OvqdeZ//+/eZ5hwUKFDAPcD5w4IBX3fUJ9voQWK3ffffdJ6NHj5bk5GSv6+rP8PTTT5vrVqpUSb744gt3/bXeqnDhwqasPmgWQCbRFcEBwFcdPXrUlTNnTtfEiRNdBw8edG3fvt01bdo01/nz513//ve/XaVLl3Z98sknrl9++cW8FilSxDVnzhzzvVpe/8xVrVrVtWzZMld8fLyrbdu2rrCwMFdSUpIrMTHRNXnyZFdQUJDr2LFjZtPrKi0zadIkdz30OmXKlHEtXLjQXKd169aucuXKuZo0aeJasWKFa/fu3a66deu6WrZs6f6e9evXm2trfQ4cOOBatWqV+Z5Ro0Z5Xbds2bKuBQsWuPbt2+fq16+fq2DBgq7Tp0+7kpOTzc+kZfQ9tX4JCQl39fcP4P8jNAHwaXFxcSY0HDp0KNW5ChUqmLDhacyYMa569ep5haaZM2e6z+/atcsc27Nnj9mfPXu2Kzg4ONW10wpNw4cPd+/HxsaaYx988IH72EcffeTKmzeve79p06auf/zjH17X/fDDD03Qu9F1L1y4YI599dVXZn/NmjVm/8yZMxa/LQAZiTFNAHyadqc1bdrUdM/pU+qbN28ubdu2ldy5c5uusG7dukmPHj3c5bXrKzg42OsaNWvWdH9dunRp83ry5EnTnXc7PK9TsmRJ86r18jymD4Q9d+6cBAUFyU8//SQbN240D4p1pKSkmDKXLl0y3XHXX1e7+fR7tX4AfAuhCYBPy5Ejh6xevVo2bdokq1atkqlTp8qrr74qS5cuNefff/99iYqKSvU9nnLlyuX+WscFqWvXrt12XdK6zs2ufeHCBTOG6Zlnnkl1LR3jlNZ1nevcSf0AZCxCEwCfpyGifv36ZhsxYoSEhYWZFpyQkBD55ZdfpFOnTnd8bW2x0tafjKADwOPj46VixYp/qH4qo+oIwB6hCYBP27Jli8TExJhuuRIlSpj9U6dOmdlr2orTr18/0x3XsmVLSUxMlO+//17OnDkj0dHRVtfXWXLaIqTvoV2B2mXmdJv9URrwdLbdvffea7oUAwMDTZfdzp07ZezYsVbX0ICooXHZsmXSqlUrM4OwYMGC6VI/ALeHJQcA+DQd37N+/XoTGCpXrizDhw+XCRMmyGOPPSbdu3c30/Vnz55txhY98sgjZrHK8uXLW19flwno1auXtGvXzqzNNH78+HSru47B0rCj3Yp16tSRunXryqRJk0wQslWmTBkTDocOHWrGTPXt2zfd6gfg9gToaPDb/B4AAIBsh5YmAAAAC4QmAAAAC4QmAAAAC4QmAAAAC4QmAAAAC4QmAAAAC4QmAAAAC4QmAAAAC4QmAAAAC4QmAAAAC4QmAAAAubX/B8ogIvypUX7xAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x='sentiment', data=movie_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf4cae5-4c62-4782-9a0c-807e46b2a6be",
   "metadata": {},
   "source": [
    " The data we have is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a2b1180-4b73-4359-9567-dbe2f41b058e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f90e4278-7c70-4a0a-91a9-560b002dfdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\johns\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f1f74c76-bf96-4a39-8485-597a49fd6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "def6578a-89d4-4926-a24b-909e6d4d03cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = text.lower()\n",
    "        \n",
    "        # Remove html tags\n",
    "    \n",
    "\n",
    "        # Remove punctuations and numbers\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "        \n",
    "        # Single character removal\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)  # When we remove apostrophe from the word \"Mark's\", the apostrophe is replaced by an empty space. Hence, we are left with single character \"s\" that we are removing here.\n",
    "\n",
    "        # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Next, we remove all the single characters and replace it by a space which creates multiple spaces in our text. Finally, we remove the multiple spaces from our text as well.\n",
    "        \n",
    "        # Remove Stopwords\n",
    "\n",
    "    words = text.split()  # Split the text into words\n",
    "    filtered_words = [word for word in words if word not in stopwords_list]\n",
    "    return ' '.join(filtered_words)\n",
    "   \n",
    "\n",
    "#review = remove_html_tags(movie_reviews['review'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7b4e3bc-b7d6-4833-8667-b9c83e745986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews['sentiment'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6cf24d7e-e59e-4d4c-9ce2-0ce6750ec215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewers mentioned watching oz episode hooked right exactly happened first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use word called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home many aryans muslims gangstas latinos christians italians irish scuffles death stares dodgy dealings shady agreements never far away would say main appeal show due fact goes shows dare forget pretty pictures painted mainstream audiences forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards sold nickel inmates kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "for review in movie_reviews['review']:\n",
    "    X.append(preprocess(review))\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "169b2a10-5914-4dd7-b86f-79c29e4be968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c87e846c-329e-4011-a001-d9a797948795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels\n",
    "y = label_encoder.fit_transform(movie_reviews['sentiment'])\n",
    "\n",
    "y[0]  # Output: [1 0 1 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "442975f9-c2d6-4cf0-8dad-654258f0eec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94ba1cf5-35b1-49b1-a31b-84ddd145549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "db43ab29-d735-4885-928e-8880feaea254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 101245 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text data\n",
    "max_words = 18000  # Maximum vocabulary size\n",
    "max_len = 300  # Maximum length of sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "word_index = tokenizer.word_index\n",
    "print(f\"Found {len(word_index)} unique tokens.\")\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# Convert labels to numpy array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "447eaf04-0cb6-4285-b81d-3c4edcc70061",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300  # You can choose 50, 100, 200, or 300-dimensional embeddings\n",
    "embeddings_index = {}\n",
    "with open(\"glove.6B/glove.6B.300d.txt\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "# Prepare the embedding matrix\n",
    "word_index = tokenizer.word_index  # Tokenizer from Keras\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c9227ee4-e810-4895-9808-3565ecbf2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ef962ce7-102c-4471-aea1-08f682f08718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d5f9fab-1a5a-440b-9a91-48b646794ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">30,373,800</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">219,648</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │      \u001b[38;5;34m30,373,800\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m219,648\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,593,577</span> (116.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,593,577\u001b[0m (116.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">219,777</span> (858.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m219,777\u001b[0m (858.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,373,800</span> (115.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m30,373,800\u001b[0m (115.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1, embedding_dim, weights=[embedding_matrix], trainable=False)) \n",
    "#model.add(LSTM(units=128, return_sequences=True))# Set trainable=True if you want to fine-tune the embeddings\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.build(input_shape=(None, max_len))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c621b8d3-4ebc-4edb-95da-f914c74568de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m 59/125\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 1s/step - accuracy: 0.8314 - loss: 0.3887"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[0;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstmenv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstmenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstmenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstmenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstmenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstmenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstmenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstmenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstmenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstmenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstmenv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lstmenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "batch_size = 256\n",
    "epochs = 3\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2)\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4175320c-4109-44b5-a304-4202bbd577e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d547e240-5977-4285-859e-78e12278954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc5ab4-15f1-47ab-8bf9-f2db8f1e7988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llavaenv)",
   "language": "python",
   "name": "llava"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
